{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'distutils'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpyspark\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mml\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mclassification\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m MultilayerPerceptronClassifier\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpyspark\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mml\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mregression\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RandomForestRegressor\n\u001b[1;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpyspark\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mml\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Pipeline\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpyspark\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mml\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mevaluation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m MulticlassClassificationEvaluator, RegressionEvaluator\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpyspark\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mml\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtuning\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ParamGridBuilder, CrossValidator\n",
      "File \u001b[1;32mc:\\Users\\nerea\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pyspark\\ml\\__init__.py:31\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpyspark\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mml\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     23\u001b[0m     Estimator,\n\u001b[0;32m     24\u001b[0m     Model,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     28\u001b[0m     UnaryTransformer,\n\u001b[0;32m     29\u001b[0m )\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpyspark\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mml\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpipeline\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Pipeline, PipelineModel\n\u001b[1;32m---> 31\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpyspark\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mml\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     32\u001b[0m     classification,\n\u001b[0;32m     33\u001b[0m     clustering,\n\u001b[0;32m     34\u001b[0m     evaluation,\n\u001b[0;32m     35\u001b[0m     feature,\n\u001b[0;32m     36\u001b[0m     fpm,\n\u001b[0;32m     37\u001b[0m     image,\n\u001b[0;32m     38\u001b[0m     recommendation,\n\u001b[0;32m     39\u001b[0m     regression,\n\u001b[0;32m     40\u001b[0m     stat,\n\u001b[0;32m     41\u001b[0m     tuning,\n\u001b[0;32m     42\u001b[0m     util,\n\u001b[0;32m     43\u001b[0m     linalg,\n\u001b[0;32m     44\u001b[0m     param,\n\u001b[0;32m     45\u001b[0m )\n\u001b[0;32m     46\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpyspark\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mml\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistributor\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TorchDistributor\n\u001b[0;32m     48\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m     49\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTransformer\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnaryTransformer\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     70\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTorchDistributor\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     71\u001b[0m ]\n",
      "File \u001b[1;32mc:\\Users\\nerea\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pyspark\\ml\\image.py:31\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Any, Dict, List, NoReturn, Optional, cast\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m---> 31\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdistutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mversion\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LooseVersion\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpyspark\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SparkContext\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpyspark\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msql\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtypes\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Row, StructType, _create_row, _parse_datatype_json_string\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'distutils'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.feature import StringIndexer, OneHotEncoder, VectorAssembler, MinMaxScaler, Imputer\n",
    "from pyspark.ml.classification import MultilayerPerceptronClassifier\n",
    "from pyspark.ml.regression import RandomForestRegressor\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator, RegressionEvaluator\n",
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "from pyspark.sql.types import StructType, StructField, StringType, DoubleType, IntegerType\n",
    "\n",
    "# Iniciar sesión de Spark\n",
    "spark = SparkSession.builder.appName(\"Diamonds ML Pipeline\").getOrCreate()\n",
    "\n",
    "# Parte 1: Definir el esquema y cargar los datos desde la URL\n",
    "schema = StructType([\n",
    "    StructField(\"carat\", DoubleType(), True),\n",
    "    StructField(\"cut\", StringType(), True),\n",
    "    StructField(\"color\", StringType(), True),\n",
    "    StructField(\"clarity\", StringType(), True),\n",
    "    StructField(\"depth\", DoubleType(), True),\n",
    "    StructField(\"table\", DoubleType(), True),\n",
    "    StructField(\"price\", IntegerType(), True),\n",
    "    StructField(\"x\", DoubleType(), True),\n",
    "    StructField(\"y\", DoubleType(), True),\n",
    "    StructField(\"z\", DoubleType(), True)\n",
    "])\n",
    "\n",
    "# Cargar los datos con el esquema definido\n",
    "data_url = \"https://raw.githubusercontent.com/mwaskom/seaborn-data/refs/heads/master/diamonds.csv\"\n",
    "df_spark = spark.read.csv(data_url, header=True, schema=schema)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ----- Parte 2: PIPELINE REGRESIÓN ----- \n",
    "num_features = [\"carat\", \"depth\", \"table\", \"x\", \"y\", \"z\"]\n",
    "cat_features = [\"cut\", \"color\", \"clarity\"]\n",
    "\n",
    "# Preprocesamiento\n",
    "imputer = Imputer(inputCols=num_features, outputCols=[f\"{col}_imputed\" for col in num_features])\n",
    "indexers = [StringIndexer(inputCol=col, outputCol=f\"{col}_indexed\") for col in cat_features]\n",
    "encoders = [OneHotEncoder(inputCol=f\"{col}_indexed\", outputCol=f\"{col}_encoded\") for col in cat_features]\n",
    "assembler = VectorAssembler(inputCols=[f\"{col}_imputed\" for col in num_features] + [f\"{col}_encoded\" for col in cat_features], outputCol=\"features\")\n",
    "scaler = MinMaxScaler(inputCol=\"features\", outputCol=\"scaled_features\")\n",
    "regressor = RandomForestRegressor(featuresCol=\"scaled_features\", labelCol=\"price\")\n",
    "\n",
    "# Definir el pipeline de regresión\n",
    "pipeline_reg = Pipeline(stages=[imputer] + indexers + encoders + [assembler, scaler, regressor])\n",
    "model_reg = pipeline_reg.fit(df_spark)\n",
    "predictions_reg = model_reg.transform(df_spark)\n",
    "\n",
    "# Evaluación Regresión\n",
    "evaluator_reg = RegressionEvaluator(labelCol=\"price\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "rmse = evaluator_reg.evaluate(predictions_reg)\n",
    "print(f\"RMSE del modelo de regresión: {rmse}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ----- Parte 3: PIPELINE CLASIFICACIÓN ----- \n",
    "# Ajustar el tamaño del vector de características para el clasificador\n",
    "assembler_class = VectorAssembler(inputCols=[f\"{col}_imputed\" for col in num_features] + [f\"{col}_encoded\" for col in cat_features], outputCol=\"features\")\n",
    "feature_vector_size = len(num_features) + len(cat_features)\n",
    "layers = [feature_vector_size, 5, 5, 5]  # Ejemplo: Entrada -> 3 capas ocultas -> Salida\n",
    "\n",
    "mlp = MultilayerPerceptronClassifier(featuresCol=\"features\", labelCol=\"cut_indexed\", layers=layers)\n",
    "\n",
    "# Definir el pipeline de clasificación\n",
    "pipeline_mlp = Pipeline(stages=[imputer] + indexers + encoders + [assembler_class, mlp])\n",
    "model_mlp = pipeline_mlp.fit(df_spark)\n",
    "predictions_mlp = model_mlp.transform(df_spark)\n",
    "\n",
    "# Evaluación Clasificación\n",
    "evaluator_class = MulticlassClassificationEvaluator(labelCol=\"cut_indexed\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "accuracy = evaluator_class.evaluate(predictions_mlp)\n",
    "print(f\"Precisión del modelo de clasificación MLP: {accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ----- Parte 4: GRIDSEARCH Y CROSSVALIDATION ----- \n",
    "\n",
    "# GridSearch para el modelo de regresión\n",
    "paramGrid_reg = ParamGridBuilder() \\\n",
    "    .addGrid(regressor.numTrees, [10, 20, 50]) \\\n",
    "    .addGrid(regressor.maxDepth, [5, 10, 15]) \\\n",
    "    .build()\n",
    "\n",
    "crossval_reg = CrossValidator(estimator=pipeline_reg, \n",
    "                              estimatorParamMaps=paramGrid_reg, \n",
    "                              evaluator=evaluator_reg, \n",
    "                              numFolds=3)\n",
    "\n",
    "cv_model_reg = crossval_reg.fit(df_spark)\n",
    "best_model_reg = cv_model_reg.bestModel\n",
    "print(\"GridSearch completado para el modelo de regresión. Mejor modelo obtenido.\")\n",
    "\n",
    "# GridSearch para el modelo de clasificación\n",
    "paramGrid_mlp = ParamGridBuilder() \\\n",
    "    .addGrid(mlp.maxIter, [50, 100, 200]) \\\n",
    "    .addGrid(mlp.layers, [[feature_vector_size, 5, 5, 5], [feature_vector_size, 10, 10, 5]]) \\\n",
    "    .build()\n",
    "\n",
    "crossval_mlp = CrossValidator(estimator=pipeline_mlp, \n",
    "                               estimatorParamMaps=paramGrid_mlp, \n",
    "                               evaluator=evaluator_class, \n",
    "                               numFolds=3)\n",
    "\n",
    "cv_model_mlp = crossval_mlp.fit(df_spark)\n",
    "best_model_mlp = cv_model_mlp.bestModel\n",
    "print(\"GridSearch y CrossValidation completados para el modelo de clasificación. Mejor modelo obtenido.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
